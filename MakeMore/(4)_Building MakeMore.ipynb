{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 32033\n",
      "total characters: 196113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt').read().splitlines()\n",
    "print(f'total words: {len(words)}')\n",
    "print(f'total characters: {len(\"\".join(words))}')\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stoi={'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n",
      "vocab_size=27\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary of characters and encoder/decoder (tokenizer)\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n",
    "vocab_size = len(stoi)\n",
    "print(f'{stoi=}')\n",
    "print(f'{vocab_size=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3          # context length\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w+'.':\n",
    "            X.append(context)\n",
    "            ix = stoi[ch]\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "    X, Y = torch.tensor(X), torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xval, Yval = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility fnction to compare Manual & PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()     # exact \n",
    "    app = torch.allclose(dt, t.grad)        # approx\n",
    "    maxdiff = (dt - t.grad).abs().max().item()  # max separation\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters in the model 4137\n"
     ]
    }
   ],
   "source": [
    "n_embed = 10        # dimensionality of character embedding vectors \n",
    "n_hidden = 64       # number of neurons in the hidden layer\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embed),             generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embed * block_size, n_hidden), generator=g) * (5/3) / ((n_embed * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                         generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),           generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                       generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.ones((1, n_hidden))\n",
    "bnbias = torch.zeros((1, n_hidden))\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print('number of parameters in the model', sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8239, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass\n",
    "emb = C[Xb]\n",
    "embcat = emb.view(emb.shape[0], -1)\n",
    "# Linear Layer 1\n",
    "hprebn = embcat @ W1 + b1       # pre act, pre batch norm\n",
    "# BatchNorm Layer\n",
    "bnmeani = 1/batch_size * hprebn.sum(0, keepdims=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(batch_size-1) * bndiff2.sum(0, keepdims=True)    # Bessel's correction\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact)\n",
    "# Linear Layer 2\n",
    "logits = h @ W2 + b2\n",
    "# Cross entropy loss\n",
    "logits_maxes = logits.max(1, keepdims=True).values\n",
    "norm_logits = logits - logits_maxes     # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1         # to escape weired float point calculations\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(batch_size), Yb].mean()\n",
    "\n",
    "# PyTorch back pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in [\n",
    "    logprobs, probs, counts, counts_sum, counts_sum_inv, norm_logits,\n",
    "    logits_maxes, logits, h, hpreact, bnraw, bnvar_inv, bnvar, bndiff,\n",
    "    bndiff2, hprebn, bnmeani, embcat, emb\n",
    "]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits_maxes    | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "bngain          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "bnraw           | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "bnbias          | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n",
      "bnvar_inv       | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "bndiff          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "bnvar           | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "bndiff2         | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-11\n",
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "bnmeani         | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "embcat          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "W1              | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "b1              | exact: False | approximate: True  | maxdiff: 4.6566128730773926e-09\n",
      "emb             | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "C               | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n"
     ]
    }
   ],
   "source": [
    "# Manual back prop\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(batch_size), Yb] = -1.0/batch_size\n",
    "\n",
    "dprobs = (1. / probs) * dlogprobs\n",
    "\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "\n",
    "# first part: dcounts\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "\n",
    "dcounts_sum = -(counts_sum**-2) * dcounts_sum_inv\n",
    "\n",
    "# second part: dcounts\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "\n",
    "# dnorm_logits = norm_logits.exp() * dcounts\n",
    "dnorm_logits = counts * dcounts\n",
    "\n",
    "# first part: dlogits\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "\n",
    "# second part: dlogits\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "\n",
    "dhpreact = (1. - h**2) * dh\n",
    "\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "\n",
    "# first part: dbndiff\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = (-0.5*(bnvar+1e-5)**-1.5) * dbnvar_inv\n",
    "\n",
    "dbndiff2 = (1./(batch_size-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "\n",
    "# second part: dbndiff\n",
    "dbndiff += (2*bndiff) * dbndiff2\n",
    "\n",
    "# first part: dhprebn\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0)\n",
    "\n",
    "# second part: dhprebn\n",
    "dhprebn += (1./batch_size)*torch.ones_like(dhprebn) * dbnmeani\n",
    "\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "\n",
    "demb = dembcat.view(emb.shape)\n",
    "\n",
    "dC = torch.zeros_like(C)\n",
    "\n",
    "# for k in range(Xb.shape[0]):\n",
    "#     for j in range(Xb.shape[1]):\n",
    "#         ix = Xb[k,j]\n",
    "#         dC[ix] += demb[k,j]\n",
    "dC.index_add_(0, Xb.view(-1), demb.view(-1, 10))    # compact version of for loop\n",
    "    \n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logits_maxes', dlogit_maxes, logits_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8239028453826904 diff: 2.384185791015625e-07\n",
      "logits          | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n"
     ]
    }
   ],
   "source": [
    "# backprop through forward pass but efficiently\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast.item()-loss.item()))\n",
    "\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(batch_size), Yb] -= 1\n",
    "dlogits /= batch_size\n",
    "\n",
    "cmp('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0114, 0.2017, 0.0166, 0.0328, 0.0601, 0.0169, 0.0098, 0.0129, 0.0323,\n",
       "        0.0222, 0.0596, 0.0070, 0.0209, 0.0054, 0.0204, 0.0195, 0.0248, 0.0057,\n",
       "        0.0021, 0.0161, 0.1435, 0.0426, 0.0747, 0.0135, 0.0041, 0.0603, 0.0631],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0114, -0.7983,  0.0166,  0.0328,  0.0601,  0.0169,  0.0098,  0.0129,\n",
       "         0.0323,  0.0222,  0.0596,  0.0070,  0.0209,  0.0054,  0.0204,  0.0195,\n",
       "         0.0248,  0.0057,  0.0021,  0.0161,  0.1435,  0.0426,  0.0747,  0.0135,\n",
       "         0.0041,  0.0603,  0.0631], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcc809e73d0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n"
     ]
    }
   ],
   "source": [
    "# backprop through batchnorm but efficiently\n",
    "dhprebn = bngain*bnvar_inv/batch_size * (batch_size*dhpreact - dhpreact.sum(0) - batch_size/(batch_size-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Layer MLP with compact code & worked out backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def manual_grads(n, logits, Yb, C, W1, W2, bngain):\n",
    "def manual_grads():\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1. - h**2) * dh\n",
    "    # batchNorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/batch_size * (batch_size*dhpreact - dhpreact.sum(0) - batch_size/(batch_size-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer backprop\n",
    "    dembcat = dhprebn @ W1.T \n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding \n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    # dC.index_add_(0, Xb.view(-1), demb.view(-1, 10))    # compact version of for loop\n",
    "    for k in range(Xb.shape[0]):\n",
    "        for j in range(Xb.shape[1]):\n",
    "            ix = Xb[k,j]\n",
    "            dC[ix] += demb[k,j]\n",
    "    return [dC, dW1, db1, dW2, db2, dbngain, dbnbias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters in the model 12297\n",
      "      0/ 200000: 3.8279\n",
      "  10000/ 200000: 2.1609\n",
      "  20000/ 200000: 2.4227\n",
      "  30000/ 200000: 2.4362\n",
      "  40000/ 200000: 2.0088\n",
      "  50000/ 200000: 2.4084\n",
      "  60000/ 200000: 2.4508\n",
      "  70000/ 200000: 2.1090\n",
      "  80000/ 200000: 2.3592\n",
      "  90000/ 200000: 2.2353\n",
      " 100000/ 200000: 1.9750\n",
      " 110000/ 200000: 2.3438\n",
      " 120000/ 200000: 2.0156\n",
      " 130000/ 200000: 2.4772\n",
      " 140000/ 200000: 2.3107\n",
      " 150000/ 200000: 2.1108\n",
      " 160000/ 200000: 1.9497\n",
      " 170000/ 200000: 1.8004\n",
      " 180000/ 200000: 2.0284\n",
      " 190000/ 200000: 1.8848\n"
     ]
    }
   ],
   "source": [
    "n_embed = 10        # dimensionality of character embedding vectors \n",
    "n_hidden = 200       # number of neurons in the hidden layer\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embed),             generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embed * block_size, n_hidden), generator=g) * (5/3) / ((n_embed * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                         generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),           generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                       generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.ones((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.zeros((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print('number of parameters in the model', sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written\n",
    "# with torch.no_grad():\n",
    "\n",
    "# optimization\n",
    "for i in range(max_steps):\n",
    "\n",
    "    # minibatch construction\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size, ), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix]       # batch X, Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb]             # embed characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concat the vectors\n",
    "    # Linear Layer\n",
    "    hprebn = embcat @ W1 + b1       # hidden layer pre-activaton\n",
    "    # BatchNorm Layer\n",
    "    # -----------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -----------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Yb)\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    # loss.backward()\n",
    "\n",
    "    # manual backprop\n",
    "    # -----------\n",
    "    grads = manual_grads() # [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # ------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "        # p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "        p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "    # if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check your gradients\n",
    "# for p, g in zip(parameters, grads):\n",
    "#     cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # pass the training set through\n",
    "    emb = C[Xtr]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    # measure the mean/std over the entire training set\n",
    "    bnmean = hpreact.mean(0, keepdim=True)\n",
    "    bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.0673816204071045\n",
      "val 2.1062190532684326\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "@torch.no_grad()\n",
    "def split_loss(split):\n",
    "    x, y = {\n",
    "        'train': (Xtr, Ytr),\n",
    "        'val': (Xval, Yval),\n",
    "        'test': (Xte, Yte)\n",
    "    }[split]\n",
    "    emb = C[x]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    hpreact = bngain * (hpreact-bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "    h = torch.tanh(hpreact)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my train loss:        2.0673816204071045\n",
    "# my val loss:          2.1062190532684326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "renix.\n",
      "adeyani.\n",
      "jozleigh.\n",
      "wusef.\n",
      "fam.\n",
      "icie.\n",
      "shubirshades.\n",
      "qui.\n",
      "eza.\n",
      "jasiaw.\n",
      "axfoon.\n",
      "corie.\n",
      "gibveli.\n",
      "nyleen.\n",
      "foody.\n",
      "sii.\n",
      "tro.\n",
      "gla.\n",
      "whalexxandreekrud.\n",
      "xallu.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0] * block_size  # context length\n",
    "    while True:\n",
    "        # ----------------------------------\n",
    "        # forward pass\n",
    "        emb = C[torch.tensor([context])]    # embedding\n",
    "        embcat = emb.view(emb.shape[0], -1)\n",
    "        hpreact = embcat @ W1 + b1\n",
    "        hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5\n",
    "        h = torch.tanh(hpreact)\n",
    "        logits = h @ W2 + b2\n",
    "        # ----------------------------------\n",
    "        # Sample\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
